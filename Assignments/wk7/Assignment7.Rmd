---
title: "Working with XML and JSON in R"
author: "Justin Williams"
date: "3/20/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load-packages, message=FALSE}
library(tidyverse)
library(RCurl)
library(XML)
library(jsonlite)
library(rvest)
library(xml2)
```

## Overview

We were asked to pick three of our favorite books on one of our favorite subjects.
<br>
Basic requirements were:
  - at least one of the books should have more than one author
  - for each book, include the title, authors, and two or three other        attributes that we find interesting.
  - Take the information that we've selected, and separately create three    files which store the bookâ€™s information in:
    - HTML (using an html table)
    - XML
    - JSON 
<br>
Write R code, using our packages of choice, to load the information from each of the three sources into separate R data frames. 

**Question**
<br>
*Are the three data frames identical?*
<br>
**Deliverable**
<br>
Three source files and R code. 

### Steps
<br>
1. Select books:
| Rank 	| Title 	| Author(s) 	| Year Pub 	| Topic(s) 	|
|:---:	|:---:	|:---:	|:---:	|:---:	|
| 1 	| Diet for a New America 	| John Robbins 	| 1987 	| diet, health, vegetarian, vegan, animal rights 	|
| 2 	| The Third Industrial Revolution 	| Jeremy Rifkin 	| 2011 	| economics, renewable energy, new energy regime, lateral thinking, digital revolution 	|
| 3 	| Another Economy is Possible 	| Manuel castells, Sarah Banet-Weiser, Sviatlana Hlebik, Giorgos Kallis, Sarah Pink, Kirsten Seale, Lisa J. Servon, Lana Swartz, Angelos Varvarousis 	| 2008 	| economics, sharing economy, alternative economic practices, cooperatives, barter networks 	|
<br>
2. Create files in each format 
  - This was done via `RStudio` IDE
<br>
3. Host files 
  - Github was chosen to host each file
  
4. Import in R
  - Write code to import each file into a valid data frame format in R
  
5. Conclusion

## Load data

```{r get-links}
books_html <- "https://raw.githubusercontent.com/justinm0rgan/data607/main/Assignments/wk7/books.html"
books_xml <- "https://raw.githubusercontent.com/justinm0rgan/data607/main/Assignments/wk7/books.xml"
books_json <- "https://raw.githubusercontent.com/justinm0rgan/data607/main/Assignments/wk7/books.json"
```

### HTML

```{r import-html}
# extract link of html file
books_html <- getURL(books_html)

# create df from html table
df_html <- books_html %>% 
  readHTMLTable()

df_html
```

### XML

```{r import-xml}
# extract link of xml file
books_xml <- getURL(books_xml)

# get authors
books_xml %>%
  read_xml %>% 
  xml_find_all(xpath = "//book//author") %>% 
  xml_text()

# get topics
books_xml %>% 
  read_xml %>% 
  xml_find_all(xpath = '//topic') %>% 
  xml_text()

books_xml %>% 
  xmlParse() %>% 
  xpathSApply(path = '//book//topic')

books_xml %>% 
  xmlParse() %>% 
  xpathSApply('//book/author[position()=1]')


books_parsed <- xmlParse(books_xml)
# build char vector with book names
books <- c("Diet for a New America", "The Third Industrial Revolution",
           "Another Economy is Possible")

(expQuery <- sprintf("//%s/book", books))


getAuthor <- function(node) {
  value <- xmlValue(node)
  book <- xmlName(xmlParent(node))
  mat <- c(books = books, value = value)
}

#as.data.frame(t(xpathSApply(books_parsed,expQuery, getAuthor)))
```
### JSON

```{r import-json}
# extract link of json file
books_json <- getURL(books_json)

# create df from json file
books_json_df <- books_json %>% 
  fromJSON() %>% 
  as.data.frame() %>% 
  rename_all(funs(str_replace(., 'books\\.',''))) %>% 
  mutate(
    author = unlist(lapply(author, 
                           function(x) str_c(x, collapse =', ' ))),
    topic = unlist(lapply(topic,
                          function(x) str_c(x, collapse = ', '))))

books_json_df
```

## Conclusion

HTML and JSON data frames both have 5 columns. JSON took a bit more of effort. I was unable to convert the XML file into a data frame. I tried the technique taught in the text, but couldn't quite get it correct.
